"""
Ana orkestratÃ¶r modÃ¼lÃ¼ - tÃ¼m bileÅŸenleri koordine eden merkezi sÄ±nÄ±f
"""
import os
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Any
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, TextColumn, BarColumn, SpinnerColumn, TimeElapsedColumn
from langdetect import detect, LangDetectException  # language detection for incorrect locale
import numpy as np
import time
import json
from datetime import datetime
import asyncio
import concurrent.futures
from functools import partial
import gc
import psutil

from ..utils.logger import LoggerMixin
from ..utils.config import Config
from ..audio.processor import AudioProcessor
from ..models.whisper_local import LocalWhisperModel
from ..models.speaker_diarization import SpeakerDiarizer
from ..models.gemini_model import GeminiAnalyzer
from ..quality.evaluator import AudioQualityEvaluator
from ..labeling.auto_labeler import AutoLabeler
from ..nlp.turkish_analyzer import TurkishNLPAnalyzer


class PodcastTranscriptionOrchestrator(LoggerMixin):
    """
    Podcast transkripsiyon sÃ¼recinin tamamÄ±nÄ± yÃ¶netir.
    Ses iÅŸleme, konuÅŸmacÄ± ayÄ±rma, transkripsiyon, kalite analizi ve Ã§Ä±ktÄ±
    oluÅŸturma adÄ±mlarÄ±nÄ± koordine eder.
    """

    def __init__(self, config_path: Optional[str] = None):
        """
        Orchestrator'Ä± baÅŸlatÄ±r.

        Args:
            config_path: KonfigÃ¼rasyon dosyasÄ±nÄ±n yolu.
        """
        super().__init__()
        self.config = Config(config_path)
        self.console = Console()
        
        # BileÅŸenleri baÅŸlat
        try:
            self.log_info("AudioProcessor baÅŸlatÄ±ldÄ±")
            self.audio_processor = AudioProcessor(self.config)
            
            self.log_info("LocalWhisperModel baÅŸlatÄ±ldÄ±")
            self.whisper_model = LocalWhisperModel(self.config)
            
            self.log_info("SpeakerDiarizer baÅŸlatÄ±ldÄ±")
            self.speaker_diarizer = SpeakerDiarizer(self.config)
            
            self.log_info("GeminiAnalyzer baÅŸlatÄ±ldÄ±")
            self.gemini_analyzer = GeminiAnalyzer(self.config)
            
            self.log_info("AudioQualityEvaluator baÅŸlatÄ±ldÄ±")
            self.quality_evaluator = AudioQualityEvaluator(self.config)
            
            self.log_info("AutoLabeler baÅŸlatÄ±ldÄ±")
            self.auto_labeler = AutoLabeler(self.config)
            
            self.log_info("TurkishNLPAnalyzer baÅŸlatÄ±ldÄ±")
            self.turkish_analyzer = TurkishNLPAnalyzer(self.config.get("nlp", {}))
            
            # Sistem performans bilgileri
            performance_config = self.config.get("performance", {})
            cpu_limit = performance_config.get("cpu_usage_limit", 0.9) * 100
            self.log_info(f"ğŸ¯ CPU kullanÄ±m limiti: %{cpu_limit:.0f}")

            self.log_info("TÃ¼m bileÅŸenler baÅŸarÄ±yla baÅŸlatÄ±ldÄ±.")
            
        except Exception as e:
            self.log_error(f"BileÅŸen baÅŸlatma hatasÄ±: {e}")
            raise
    
    def process_podcast(self, audio_file: str, interactive: bool = True, save_intermediate: bool = False) -> Dict:
        """
        Ana podcast iÅŸleme fonksiyonu.

        Args:
            audio_file: Ä°ÅŸlenecek ses dosyasÄ±nÄ±n yolu.
            interactive: Ä°nteraktif mod (kullanÄ±cÄ±ya soru sorar).
            save_intermediate: Ara iÅŸlem sonuÃ§larÄ±nÄ± kaydet.

        Returns:
            Ä°ÅŸlem sonuÃ§larÄ±nÄ± iÃ§eren bir sÃ¶zlÃ¼k.
        """
        results = {}
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            console=self.console,
            transient=True
        ) as progress:
            task = progress.add_task("Ä°ÅŸlem adÄ±mlarÄ±", total=8)
            
            try:
                # 1. Ses dosyasÄ±nÄ± iÅŸle ve hazÄ±rla
                progress.update(task, description="Ses dosyasÄ± hazÄ±rlanÄ±yor...", advance=1)
                
                # Paralel ses iÅŸleme ve bilgi toplama
                with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                    # Audio info ve processing'i paralel Ã§alÄ±ÅŸtÄ±r
                    audio_info_future = executor.submit(self.audio_processor.get_audio_info, audio_file)
                    audio_load_future = executor.submit(self.audio_processor.load_audio, audio_file)
                    
                    # SonuÃ§larÄ± al
                    audio_info = audio_info_future.result()
                    audio_data, sr = audio_load_future.result()
                    
                    # Audio processing pipeline'Ä±nÄ± paralel Ã§alÄ±ÅŸtÄ±r
                    processing_futures = []
                    if self.config.get("audio_processing.noise_reduction.enabled", False):
                        processing_futures.append(
                            executor.submit(self.audio_processor.reduce_noise, audio_data, sr)
                        )
                    
                    # Processing sonuÃ§larÄ±nÄ± al
                    if processing_futures:
                        audio_data = processing_futures[0].result()
                    
                    # Normalizasyon
                    if self.config.get("audio_processing.normalization.enabled", False):
                        target_lufs = self.config.get("audio_processing.normalization.target_lufs", -23.0)
                        audio_data = self.audio_processor.normalize_audio(audio_data, target_lufs)
                    
                    # Ä°ÅŸlenmiÅŸ sesi geÃ§ici dosyaya kaydet
                    processed_audio_path = self.audio_processor.save_temp_audio(audio_data, sr)
                    audio_info["processed_path"] = processed_audio_path

                    if interactive:
                        self._display_audio_info(audio_info)

                # 2. Ses Kalitesi DeÄŸerlendirmesi
                progress.update(task, description="Ses kalitesi Ã¶lÃ§Ã¼lÃ¼yor...", advance=1)
                quality_result = self.quality_evaluator.evaluate_audio_quality(processed_audio_path)
                results["audio_quality"] = quality_result
                if interactive:
                    self._display_quality_assessment(quality_result)

                # 3. KonuÅŸmacÄ± ayÄ±rma (Ã§ok kÄ±sa dosyalarda optimize et)
                progress.update(task, description="KonuÅŸmacÄ±lar tespit ediliyor...", advance=1)
                if audio_info.get('sure_saniye', 0) < 5:
                    self.log_info("Ses dosyasÄ± 5 saniyeden kÄ±sa, performans iÃ§in konuÅŸmacÄ± ayÄ±rma atlanÄ±yor.")
                    speaker_result = {
                        "segments": [{
                            "start_time": 0,
                            "end_time": audio_info.get('sure_saniye', 0),
                            "duration": audio_info.get('sure_saniye', 0),
                            "speaker": "SPEAKER_00"
                        }],
                        "speakers": ["SPEAKER_00"],
                        "speaker_count": 1,
                        "main_speaker": "SPEAKER_00",
                        "skipped": True
                    }
                else:
                    try:
                        speaker_result = self.speaker_diarizer.diarize_audio(processed_audio_path)
                    except (UnicodeEncodeError, ConnectionError, ValueError) as e:
                        self.log_error(f"KonuÅŸmacÄ± ayÄ±rma baÅŸarÄ±sÄ±z: {e}")
                        self.log_warning("Single speaker moduna geÃ§iliyor...")
                        speaker_result = {
                            "segments": [{
                                "start_time": 0,
                                "end_time": audio_info.get('sure_saniye', 0),
                                "duration": audio_info.get('sure_saniye', 0),
                                "speaker": "SPEAKER_00"
                            }],
                            "speakers": ["SPEAKER_00"],
                            "speaker_count": 1,
                            "main_speaker": "SPEAKER_00",
                            "fallback": True,
                            "fallback_reason": str(e)
                        }
                results["speaker_diarization"] = speaker_result

                if interactive:
                    # KonuÅŸmacÄ± bilgilerini gÃ¶ster
                    temp_main_speaker = speaker_result.get("main_speaker", speaker_result.get("speakers", ["SPEAKER_00"])[0])
                    self._display_speaker_info(speaker_result, temp_main_speaker)
                    
                    # KullanÄ±cÄ±dan ana konuÅŸmacÄ± seÃ§imini al
                    main_speaker = self._interactive_main_speaker_selection(speaker_result)
                    results["selected_main_speaker"] = main_speaker
                else:
                    # Non-interactive modda varsayÄ±lan ana konuÅŸmacÄ±yÄ± kullan
                    main_speaker = speaker_result.get("main_speaker", speaker_result.get("speakers", ["SPEAKER_00"])[0])
                    results["selected_main_speaker"] = main_speaker

                # 4. Transkripsiyon
                progress.update(task, description="Transkripsiyon baÅŸlÄ±yor...", advance=1)
                
                # Paralel transkripsiyon seÃ§enekleri
                enable_comparison = self.config.get("transcription.enable_model_comparison", False)
                
                if enable_comparison:
                    # Ã‡oklu model karÅŸÄ±laÅŸtÄ±rmasÄ±
                    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                        transcription_futures = {}
                        
                        # TÃ¼m mevcut modelleri paralel Ã§alÄ±ÅŸtÄ±r
                        if hasattr(self, 'whisper_openai'):
                            transcription_futures["whisper_openai"] = executor.submit(
                                self.whisper_openai.transcribe_audio, processed_audio_path
                            )
                        if hasattr(self, 'whisper_local'):
                            transcription_futures["whisper_local"] = executor.submit(
                                self.whisper_local.transcribe_audio, processed_audio_path
                            )
                        # Ana whisper_transcriber de dahil et
                        transcription_futures["whisper_transcriber"] = executor.submit(
                            self.whisper_model.transcribe_with_speaker_diarization,
                            processed_audio_path, speaker_result
                        )
                        
                        # SonuÃ§larÄ± topla
                        transcription_results = {}
                        for model_name, future in transcription_futures.items():
                            try:
                                transcription_results[model_name] = future.result(timeout=300)
                                self.log_info(f"{model_name} transkripsiyon tamamlandÄ±")
                            except Exception as e:
                                self.log_error(f"{model_name} transkripsiyon hatasÄ±: {e}")
                                transcription_results[model_name] = None
                        
                        # Ana sonucu kullan (whisper_transcriber)
                        transcription_result = transcription_results.get("whisper_transcriber")
                        results["model_comparison"] = transcription_results
                        
                else:
                    # Standart tek model kullanÄ±mÄ±
                    progress.update(task, description="Transkripsiyon yapÄ±lÄ±yor...", advance=1)
                    transcription_result = self.whisper_model.transcribe_with_speaker_diarization(
                        processed_audio_path, speaker_result
                    )
                
                # Sadece ana konuÅŸmacÄ±yÄ± transkribe etme kuralÄ±
                if main_speaker and speaker_result.get("speaker_count", 0) > 1:
                    self.log_info(f"YalnÄ±zca ana konuÅŸmacÄ± ({main_speaker}) iÃ§in transkripsiyon filtreleniyor...")
                    original_segments = transcription_result.get("segments", [])
                    filtered_segments = [
                        seg for seg in original_segments if seg.get("speaker") == main_speaker
                    ]
                    
                    # FiltrelenmiÅŸ segmentlerden metni yeniden oluÅŸtur
                    filtered_text = " ".join([seg.get("text", "").strip() for seg in filtered_segments])
                    
                    transcription_result["segments"] = filtered_segments
                    transcription_result["text"] = filtered_text
                    transcription_result["is_filtered_by_main_speaker"] = True
                    self.log_info(f"FiltrelenmiÅŸ metin: {filtered_text[:100]}...")

                results["transcription"] = transcription_result
                
                # YanlÄ±ÅŸ dil kuralÄ± uygulamasÄ±
                self._apply_foreign_language_rule(transcription_result)

                # Kesilme tespiti
                truncation_info = self._detect_truncation(audio_data, sr)
                if truncation_info["is_truncated"]:
                    self.log_info(truncation_info["reason"])
                results["truncation_info"] = truncation_info

                # 5. GeliÅŸmiÅŸ Kalite Analizi (Gemini)
                progress.update(task, description="AI kalite analizi yapÄ±lÄ±yor...", advance=1)
                
                # 5-8. Paralel kalite analizi ve dÃ¼zeltme iÅŸlemleri
                with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                    # EÅŸ zamanlÄ± iÅŸlemler
                    labeling_future = executor.submit(
                        self.auto_labeler.suggest_labels,
                        transcription_result, quality_result, speaker_result, truncation_info
                    )
                    
                    polly_future = executor.submit(
                        self.auto_labeler.process_polly_compliance, transcription_result
                    )
                    
                    multiple_voices_future = executor.submit(
                        self.auto_labeler.analyze_multiple_voices_compliance,
                        speaker_result, quality_result
                    )
                    
                    wrong_lang_future = None
                    if transcription_result.get("text"):
                        wrong_lang_future = executor.submit(
                            self._check_wrong_language_polly_rule, transcription_result["text"]
                        )
                    
                    # Ä°lk aÅŸama sonuÃ§larÄ±nÄ± al
                    label_suggestions_result = labeling_future.result()
                    transcription_result = polly_future.result()
                    multiple_voices_analysis = multiple_voices_future.result()
                    
                    if wrong_lang_future:
                        wrong_language_check = wrong_lang_future.result()
                        results["wrong_language_analysis"] = wrong_language_check
                    
                    results["multiple_voices_analysis"] = multiple_voices_analysis
                    results["label_suggestions"] = label_suggestions_result
                    
                    # Label Ã¶nerilerini al
                    label_suggestions_list = label_suggestions_result.get("suggestions", [])
                    
                    # Ä°kinci aÅŸama: Gemini analizleri paralel
                    gemini_quality_future = executor.submit(
                        self.gemini_analyzer.evaluate_audio_and_transcription_quality,
                        transcription_result["text"], audio_info, label_suggestions_list
                    )
                    
                    correction_future = executor.submit(
                        self.gemini_analyzer.correct_entities_and_abbreviations,
                        transcription_result["text"]
                    )
                    
                    accent_future = executor.submit(
                        self.gemini_analyzer.detect_accent,
                        transcription_result["text"]
                    )
                    
                    # Ä°kinci aÅŸama sonuÃ§larÄ±nÄ± al
                    gemini_analysis = gemini_quality_future.result()
                    corrected_text = correction_future.result()
                    heavy_accent_flag = accent_future.result()
                    
                    # SonuÃ§larÄ± ata
                    results["gemini_analysis"] = gemini_analysis
                    transcription_result["text"] = corrected_text
                    results["corrected_transcription"] = corrected_text
                    results["heavy_accent_analysis"] = heavy_accent_flag
                    
                if heavy_accent_flag.get("heavy_accent"):
                    self.log_info("AÄŸÄ±r aksan bayraÄŸÄ± aktif edildi.")
                    
                    self.log_info("Paralel kalite analizi ve dÃ¼zeltme iÅŸlemleri tamamlandÄ±.")
                
                progress.update(task, description="Kalite analizi tamamlandÄ±", advance=1)
            
                # Son transkripti oluÅŸtur
                final_transcription_text = self._generate_final_transcription_text(results)
                results["final_transcription"] = final_transcription_text
                
                # NLP analizi
                progress.update(task, description="NLP analizi yapÄ±lÄ±yor...", advance=1)
                if final_transcription_text:
                    # Paralel NLP analizi
                    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                        # Ana NLP analizi
                        nlp_future = executor.submit(
                            self.turkish_analyzer.analyze_text, final_transcription_text
                        )
                        
                        # TÃ¼rkÃ§e pattern analizi
                        turkish_future = None
                        if hasattr(self.turkish_analyzer, 'detect_turkish_patterns'):
                            turkish_future = executor.submit(
                                self.turkish_analyzer.detect_turkish_patterns, final_transcription_text
                            )
                        
                        # SonuÃ§larÄ± al
                        nlp_results = nlp_future.result()
                        
                        if turkish_future:
                            turkish_patterns = turkish_future.result()
                        nlp_results["turkish_patterns"] = turkish_patterns
                        
                        # TÃ¼rkÃ§e pattern'lara gÃ¶re kalite skorlarÄ± gÃ¼ncelle
                        quality_indicators = turkish_patterns.get("quality_indicators", {})
                        if quality_indicators:
                            self.log_info(f"TÃ¼rkÃ§e konuÅŸma kalitesi: Formal={quality_indicators.get('is_formal_speech', False)}, "
                                        f"TereddÃ¼t={quality_indicators.get('has_hesitation', False)}, "
                                        f"AÄŸÄ±z={quality_indicators.get('has_dialect', False)}")
                            
                            # TÃ¼rkÃ§e pattern'lara gÃ¶re ek etiket Ã¶nerileri
                            turkish_label_suggestions = self._generate_turkish_label_suggestions(turkish_patterns)
                            if turkish_label_suggestions:
                                existing_suggestions = results.get("label_suggestions", {}).get("suggestions", [])
                                existing_suggestions.extend(turkish_label_suggestions)
                                self.log_info(f"TÃ¼rkÃ§e pattern'larÄ±na gÃ¶re {len(turkish_label_suggestions)} ek etiket Ã¶nerisi eklendi")
                    
                    results["nlp_analysis"] = nlp_results
                else:
                    results["nlp_analysis"] = {}

                progress.update(task, description="Ä°ÅŸlem tamamlandÄ±", advance=1)

                # Bellek ve dosya temizliÄŸi
                self._cleanup_temp_files(processed_audio_path)
                self._optimize_memory_usage()

            except Exception as e:
                self.log_error(f"Ä°ÅŸlem sÄ±rasÄ±nda hata: {e}", exc_info=True)
                results["error"] = str(e)
            
        return results

    def _display_audio_info(self, audio_info: Dict):
        """Ses dosyasÄ± bilgilerini konsola yazdÄ±r"""
        try:
            table = Table(title="ğŸµ Ses DosyasÄ± Bilgileri", style="cyan")
            table.add_column("Ã–zellik", style="bold blue")
            table.add_column("DeÄŸer", style="green")
            
            # Temel bilgiler
            table.add_row("ğŸ“ Dosya", audio_info.get("dosya_adi", "Bilinmiyor"))
            table.add_row("â±ï¸ SÃ¼re", f"{audio_info.get('sure_saniye', 0):.1f} saniye")
            table.add_row("ğŸ”Š Ã–rnekleme HÄ±zÄ±", f"{audio_info.get('ornek_hizi', 0)} Hz")
            table.add_row("ğŸ“» Kanal SayÄ±sÄ±", str(audio_info.get("kanal_sayisi", 0)))
            table.add_row("ğŸ’¾ Dosya Boyutu", f"{audio_info.get('dosya_boyutu_mb', 0):.1f} MB")
            
            # Ses kalitesi gÃ¶stergeleri
            if "ortalama_dB" in audio_info:
                table.add_row("ğŸ“ˆ Ortalama dB", f"{audio_info['ortalama_dB']:.1f} dB")
            if "maksimum_dB" in audio_info:
                table.add_row("ğŸ“Š Maksimum dB", f"{audio_info['maksimum_dB']:.1f} dB")
                
            self.console.print(table)
            
        except Exception as e:
            self.log_error(f"Audio info display hatasÄ±: {e}")
    
    def _optimize_memory_usage(self):
        """Bellek kullanÄ±mÄ±nÄ± optimize et"""
        try:
            # Garbage collection yap
            collected = gc.collect()
            
            # Bellek kullanÄ±m bilgisi
            process = psutil.Process(os.getpid())
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            self.log_info(f"Bellek optimizasyonu: {collected} nesne temizlendi, mevcut kullanÄ±m: {memory_mb:.1f} MB")
            
            # 1GB'dan fazla kullanÄ±mda uyarÄ± ver
            if memory_mb > 1024:
                self.log_warning(f"YÃ¼ksek bellek kullanÄ±mÄ± tespit edildi: {memory_mb:.1f} MB")
                
        except Exception as e:
            self.log_error(f"Bellek optimizasyon hatasÄ±: {e}")
    
    def _cleanup_temp_files(self, processed_audio_path: str = None):
        """GeÃ§ici dosyalarÄ± temizle"""
        try:
            if processed_audio_path and os.path.exists(processed_audio_path):
                os.remove(processed_audio_path)
                self.log_info(f"GeÃ§ici ses dosyasÄ± temizlendi: {processed_audio_path}")
                
            # temp/ klasÃ¶rÃ¼ndeki eski dosyalarÄ± temizle
            temp_dir = Path("temp")
            if temp_dir.exists():
                for temp_file in temp_dir.glob("*.wav"):
                    file_age = time.time() - temp_file.stat().st_mtime
                    if file_age > 3600:  # 1 saatten eski
                        temp_file.unlink()
                        self.log_info(f"Eski geÃ§ici dosya temizlendi: {temp_file}")
                        
        except Exception as e:
            self.log_error(f"Dosya temizleme hatasÄ±: {e}")
    
    def _display_quality_assessment(self, quality_result: Dict):
        """Kalite deÄŸerlendirmesi sonuÃ§larÄ±nÄ± konsola yazdÄ±r"""
        try:
            table = Table(title="ğŸ” Ses Kalitesi Analizi", style="yellow")
            table.add_column("Metrik", style="bold blue")
            table.add_column("DeÄŸer", style="green")
            table.add_column("Durum", style="bold")
            
            # Temel kalite metrikleri
            snr = quality_result.get("snr_db", 0)
            snr_status = "âœ… Ä°yi" if snr > 10 else "âš ï¸ Orta" if snr > 5 else "âŒ DÃ¼ÅŸÃ¼k"
            table.add_row("ğŸ“ˆ Sinyal/GÃ¼rÃ¼ltÃ¼ OranÄ±", f"{snr:.1f} dB", snr_status)
            
            clarity = quality_result.get("clarity_score", 0)
            clarity_status = "âœ… Net" if clarity > 0.7 else "âš ï¸ Orta" if clarity > 0.4 else "âŒ Belirsiz"
            table.add_row("ğŸ”Š Netlik Skoru", f"{clarity:.2f}", clarity_status)
            
            # Frekans analizi
            freq_balance = quality_result.get("frequency_balance", {})
            if freq_balance:
                for freq_name, score in freq_balance.items():
                    freq_status = "âœ…" if score > 0.6 else "âš ï¸" if score > 0.3 else "âŒ"
                    table.add_row(f"ğŸ“Š {freq_name.title()}", f"{score:.2f}", freq_status)
            
            # Categorical assessment sonuÃ§larÄ±
            categorical = quality_result.get("categorical_assessment", {})
            if categorical:
                table.add_row("", "", "")  # BoÅŸ satÄ±r
                table.add_row("ğŸ·ï¸ [bold]Kategori DeÄŸerlendirmesi[/bold]", "", "")
                
                categories = {
                    "belirsiz_ses": "ğŸ¯ Ses NetliÄŸi",
                    "agir_aksan": "ğŸ—£ï¸ Aksan Durumu", 
                    "yanlis_dil": "ğŸŒ Dil Uyumu",
                    "sentezlenmis": "ğŸ¤– Yapay Ses",
                    "coklu_ses": "ğŸ‘¥ Ã‡oklu KonuÅŸmacÄ±"
                }
                
                for key, display_name in categories.items():
                    value = categorical.get(key, False)
                    status = "âŒ Sorunlu" if value else "âœ… Normal"
                    table.add_row(display_name, "Evet" if value else "HayÄ±r", status)
            
            self.console.print(table)
            
            # Ã–nemli uyarÄ±lar
            warnings = []
            if snr < 5:
                warnings.append("âš ï¸ DÃ¼ÅŸÃ¼k sinyal/gÃ¼rÃ¼ltÃ¼ oranÄ± - transkripsiyon kalitesi etkilenebilir")
            if clarity < 0.4:
                warnings.append("âš ï¸ DÃ¼ÅŸÃ¼k ses netliÄŸi - manuel dÃ¼zeltme gerekebilir")
            if categorical.get("coklu_ses", False):
                warnings.append("ğŸ‘¥ Ã‡oklu konuÅŸmacÄ± tespit edildi - konuÅŸmacÄ± ayÄ±rma aktif")
                
            if warnings:
                self.console.print("\n[bold yellow]ğŸš¨ Ã–nemli UyarÄ±lar:[/bold yellow]")
                for warning in warnings:
                    self.console.print(f"  {warning}")
                
        except Exception as e:
            self.log_error(f"Quality assessment display hatasÄ±: {e}")

    def _display_speaker_info(self, speaker_result: Dict, main_speaker: str):
        """KonuÅŸmacÄ± bilgilerini konsola yazdÄ±r"""
        try:
            table = Table(title="ğŸ‘¥ KonuÅŸmacÄ± Analizi", style="magenta")
            table.add_column("KonuÅŸmacÄ±", style="bold blue")
            table.add_column("KonuÅŸma SÃ¼resi", style="green")
            table.add_column("YÃ¼zde", style="yellow")
            table.add_column("Segment SayÄ±sÄ±", style="cyan")
            
            speakers = speaker_result.get("speakers", [])
            segments = speaker_result.get("segments", [])
            
            # Her konuÅŸmacÄ± iÃ§in istatistikler
            speaker_stats = {}
            total_duration = 0
            
            for segment in segments:
                speaker = segment.get("speaker", "UNKNOWN")
                duration = segment.get("duration", 0)
                
                if speaker not in speaker_stats:
                    speaker_stats[speaker] = {"duration": 0, "segments": 0}
                
                speaker_stats[speaker]["duration"] += duration
                speaker_stats[speaker]["segments"] += 1
                total_duration += duration
            
            # Tabloyu doldur
            for speaker in sorted(speaker_stats.keys()):
                stats = speaker_stats[speaker]
                duration = stats["duration"]
                segments_count = stats["segments"]
                percentage = (duration / total_duration * 100) if total_duration > 0 else 0
                
                # Ana konuÅŸmacÄ±yÄ± vurgula
                speaker_name = f"ğŸ‘‘ {speaker}" if speaker == main_speaker else f"  {speaker}"
                
                table.add_row(
                    speaker_name,
                    f"{duration:.1f}s",
                    f"{percentage:.1f}%",
                    str(segments_count)
                )
            
            self.console.print(table)
            
            # Ã–zet bilgiler
            summary_text = f"""
ğŸ“Š [bold]Ã–zet:[/bold]
â€¢ Toplam konuÅŸmacÄ± sayÄ±sÄ±: {len(speakers)}
â€¢ Toplam segment sayÄ±sÄ±: {len(segments)}
â€¢ Toplam sÃ¼re: {total_duration:.1f} saniye
â€¢ Ana konuÅŸmacÄ±: {main_speaker}
            """
            
            self.console.print(Panel.fit(summary_text.strip(), style="blue"))
        except Exception as e:
            self.log_error(f"Speaker info display hatasÄ±: {e}")

    # ------------------------------------------------------------------
    # Ek YardÄ±mcÄ± Fonksiyonlar (basit/Ã¶zet implementasyonlar)
    # ------------------------------------------------------------------

    def _apply_foreign_language_rule(self, transcription_result: Dict):
        """YabancÄ± dil kontrolÃ¼ â€“ basit stub (detaylÄ± analiz kaldÄ±rÄ±ldÄ±)"""
        try:
            text = transcription_result.get("text", "")
            if not text:
                return
            from langdetect import detect, LangDetectException
            try:
                detected_language = detect(text)
                transcription_result["detected_language"] = detected_language
                transcription_result["language_warning"] = detected_language != "tr"
            except LangDetectException:
                transcription_result["detected_language"] = "unknown"
                transcription_result["language_warning"] = True
        except Exception as e:
            self.log_error(f"Foreign language rule hatasÄ±: {e}")

    def _generate_final_transcription_text(self, results: Dict) -> str:
        """Son transkripti (dÃ¼z metin) dÃ¶ndÃ¼rÃ¼r."""
        return self._get_final_transcription(results)

    def _get_final_transcription(self, results: Dict) -> str:
        transcription_result = results.get("transcription", {})
        return transcription_result.get("text", "")

    def _get_user_choice(self, question: str, choices: List[str]) -> str:
        """KullanÄ±cÄ± etkileÅŸimi olmayan ortamlar iÃ§in ilk seÃ§eneÄŸi dÃ¶ndÃ¼rÃ¼r."""
        return choices[0] if choices else ""

    def save_results(self, results: Dict[str, Any], output_dir: str = "output"):
        """YalnÄ±zca .txt ve .json Ã§Ä±ktÄ± oluÅŸturur (SRT/VTT kaldÄ±rÄ±ldÄ±)."""
        import json
        os.makedirs(output_dir, exist_ok=True)
        final_text = results.get("final_transcription", "")
        timestamp = datetime.now().strftime('%d-%m-%Y_%H-%M-%S')

        # ---- Dinamik Anket OluÅŸtur ----
        def checkbox(checked: bool, text: str) -> str:
            return f"[{'x' if checked else ' '}] {text}"

        aq = results.get("audio_quality", {})
        clarity = aq.get("clarity_score", 1.0)
        snr = aq.get("snr_db", 20)
        unclear_audio = clarity < 0.4 or snr < 5

        wrong_lang = False
        wl = results.get("wrong_language_analysis", {})
        if isinstance(wl, dict):
            wrong_lang = wl.get("wrong_language", False)
        else:
            # AyrÄ±ca foreign language rule
            tr = results.get("transcription", {})
            wrong_lang = tr.get("language_warning", False)

        multiple_voices = False
        spk = results.get("speaker_diarization", {})
        if isinstance(spk, dict):
            multiple_voices = spk.get("speaker_count", 1) > 1

        questionnaire_lines = [
            "\n\nPROBLEM WITH AUDIO QUESTIONS",
            "Select ALL that apply.\n",
            checkbox(unclear_audio, "User was hard to hear because of unclear audio"),
            "",
            checkbox(False, "User has heavy accent"),
            "",
            checkbox(wrong_lang, "Request is in the incorrect language for this locale"),
            "",
            checkbox(False, "Request is synthesized or recorded speech"),
            "",
            checkbox(multiple_voices, "Multiple voices in the audio"),
            ""
        ]

        questionnaire = "\n".join(questionnaire_lines)

        # Metni ve anketi birleÅŸtir
        txt_content = final_text.rstrip() + questionnaire

        # TXT
        txt_path = Path(output_dir) / f"{timestamp}.txt"
        with open(txt_path, "w", encoding="utf-8") as fp:
            fp.write(txt_content)

        # JSON (tÃ¼m sonuÃ§lar)
        json_path = Path(output_dir) / f"{timestamp}.json"
        with open(json_path, "w", encoding="utf-8") as fp:
            json.dump(results, fp, ensure_ascii=False, indent=4, default=str)

        self.log_info(f"SonuÃ§lar kaydedildi (.txt & .json): {txt_path}, {json_path}")
        return str(json_path)

    # AÅŸaÄŸÄ±daki fonksiyonlarÄ±n detaylÄ± implementasyonlarÄ± kaldÄ±rÄ±ldÄ±; temel iÅŸlevsel stub'lar eklendi

    def _interactive_main_speaker_selection(self, speaker_result: Dict) -> str:
        return speaker_result.get("main_speaker", speaker_result.get("speakers", ["SPEAKER_00"])[0])

    def format_for_editing(self, transcription_result: Dict) -> str:
        return transcription_result.get("text", "")

    def interactive_edit(self, initial_text: str) -> str:
        return initial_text

    def _detect_truncation(self, audio_data: np.ndarray, sample_rate: int, threshold: float = 0.1, duration_ms: int = 50) -> Dict:
        return {"start": False, "end": False, "is_truncated": False, "reason": "stub"}

    def _generate_turkish_label_suggestions(self, turkish_patterns: Dict) -> List[Dict]:
        return []

    def _display_correction_suggestions(self, llm_analysis: Dict, label_suggestions: Dict):
        pass

    def _generate_editing_instructions(self, llm_analysis: Dict, label_suggestions: Dict) -> str:
        return ""

    def _display_final_results(self, results: Dict):
        pass

    def _ask_user(self, question: str) -> bool:
        return True

    def _check_wrong_language_polly_rule(self, text: str) -> Dict:
        return {"wrong_language": False}

    def _save_intermediate_results(self, results: Dict, output_dir: str = "output"):
        pass

    # ---- SRT / VTT FonksiyonlarÄ± ArtÄ±k KullanÄ±lmÄ±yor ----
    def _export_srt(self, results: Dict, srt_file: Path):
        pass

    def _export_vtt(self, results: Dict, vtt_file: Path):
        pass

    def _export_speaker_labeled(self, results: Dict, labeled_file: Path):
        pass

    def _seconds_to_srt_time(self, seconds: float) -> str:
        millis = int((seconds % 1) * 1000)
        secs = int(seconds) % 60
        minutes = int(seconds // 60) % 60
        hours = int(seconds // 3600)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def _seconds_to_vtt_time(self, seconds: float) -> str:
        millis = int((seconds % 1) * 1000)
        secs = int(seconds) % 60
        minutes = int(seconds // 60) % 60
        hours = int(seconds // 3600)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"

    def _seconds_to_timestamp(self, seconds: float) -> str:
        mins = int(seconds // 60)
        secs = int(seconds) % 60
        return f"{mins:02d}:{secs:02d}"

    def _safe_speaker_diarization(self, processed_audio_path: str) -> Dict:
        return {"segments": [], "speakers": [], "speaker_count": 0, "main_speaker": "SPEAKER_00"}